{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Analysis-of-full-length-PacBio-sequencing-of-influenza-mRNAs\" data-toc-modified-id=\"Analysis-of-full-length-PacBio-sequencing-of-influenza-mRNAs-1\">Analysis of full-length PacBio sequencing of influenza mRNAs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-up-for-analysis\" data-toc-modified-id=\"Set-up-for-analysis-1.1\">Set up for analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Python-modules\" data-toc-modified-id=\"Import-Python-modules-1.1.1\">Import Python modules</a></span></li><li><span><a href=\"#Define-/-create-directories\" data-toc-modified-id=\"Define-/-create-directories-1.1.2\">Define / create directories</a></span></li><li><span><a href=\"#How-many-CPUs-to-use\" data-toc-modified-id=\"How-many-CPUs-to-use-1.1.3\">How many CPUs to use</a></span></li></ul></li><li><span><a href=\"#Build-CCSs\" data-toc-modified-id=\"Build-CCSs-1.2\">Build CCSs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-subreads-files\" data-toc-modified-id=\"Get-subreads-files-1.2.1\">Get subreads files</a></span></li><li><span><a href=\"#Run-ccs\" data-toc-modified-id=\"Run-ccs-1.2.2\">Run <code>ccs</code></a></span></li><li><span><a href=\"#Number-of-CCSs\" data-toc-modified-id=\"Number-of-CCSs-1.2.3\">Number of CCSs</a></span></li><li><span><a href=\"#CCS-accuracy-/-length\" data-toc-modified-id=\"CCS-accuracy-/-length-1.2.4\">CCS accuracy / length</a></span></li></ul></li><li><span><a href=\"#Align-CCSs-to-flu-genes\" data-toc-modified-id=\"Align-CCSs-to-flu-genes-1.3\">Align CCSs to flu genes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Barcoded-CCS-features\" data-toc-modified-id=\"Barcoded-CCS-features-1.3.1\">Barcoded CCS features</a></span></li><li><span><a href=\"#Flu-alignment-targets\" data-toc-modified-id=\"Flu-alignment-targets-1.3.2\">Flu alignment targets</a></span></li><li><span><a href=\"#Match-and-align-CCSs\" data-toc-modified-id=\"Match-and-align-CCSs-1.3.3\">Match and align CCSs</a></span></li><li><span><a href=\"#Stats-on-matching-/-alignment\" data-toc-modified-id=\"Stats-on-matching-/-alignment-1.3.4\">Stats on matching / alignment</a></span></li><li><span><a href=\"#Get-CCSs-with-gene-aligned\" data-toc-modified-id=\"Get-CCSs-with-gene-aligned-1.3.5\">Get CCSs with gene aligned</a></span></li></ul></li><li><span><a href=\"#Quality-control-alignments\" data-toc-modified-id=\"Quality-control-alignments-1.4\">Quality-control alignments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Barcode-accuracy\" data-toc-modified-id=\"Barcode-accuracy-1.4.1\">Barcode accuracy</a></span></li><li><span><a href=\"#Additional-alignments\" data-toc-modified-id=\"Additional-alignments-1.4.2\">Additional alignments</a></span></li><li><span><a href=\"#Excessive-alignment-trimming\" data-toc-modified-id=\"Excessive-alignment-trimming-1.4.3\">Excessive alignment trimming</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trimming-of-query-start\" data-toc-modified-id=\"Trimming-of-query-start-1.4.3.1\">Trimming of query start</a></span></li><li><span><a href=\"#Trimming-of-target-start\" data-toc-modified-id=\"Trimming-of-target-start-1.4.3.2\">Trimming of target start</a></span></li><li><span><a href=\"#Trimming-query-ends\" data-toc-modified-id=\"Trimming-query-ends-1.4.3.3\">Trimming query ends</a></span></li><li><span><a href=\"#Trimming-target-ends\" data-toc-modified-id=\"Trimming-target-ends-1.4.3.4\">Trimming target ends</a></span></li></ul></li><li><span><a href=\"#Get-QC-ed-alignments\" data-toc-modified-id=\"Get-QC-ed-alignments-1.4.4\">Get QC-ed alignments</a></span></li></ul></li><li><span><a href=\"#Summary-of-QC-ed-alignments\" data-toc-modified-id=\"Summary-of-QC-ed-alignments-1.5\">Summary of QC-ed alignments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-alignments-per-gene\" data-toc-modified-id=\"Number-of-alignments-per-gene-1.5.1\">Number of alignments per gene</a></span></li><li><span><a href=\"#Distribution-of-alignment-lengths\" data-toc-modified-id=\"Distribution-of-alignment-lengths-1.5.2\">Distribution of alignment lengths</a></span></li><li><span><a href=\"#Near-full-length-alignments\" data-toc-modified-id=\"Near-full-length-alignments-1.5.3\">Near full-length alignments</a></span></li></ul></li><li><span><a href=\"#Analyze-viral-barcodes\" data-toc-modified-id=\"Analyze-viral-barcodes-1.6\">Analyze viral barcodes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inspect-viral-barcodes-by-gene\" data-toc-modified-id=\"Inspect-viral-barcodes-by-gene-1.6.1\">Inspect viral barcodes by gene</a></span></li><li><span><a href=\"#Estimate-rate-of-PCR-strand-exchange\" data-toc-modified-id=\"Estimate-rate-of-PCR-strand-exchange-1.6.2\">Estimate rate of PCR strand exchange</a></span></li><li><span><a href=\"#Filter-chimeras,-assign-viral-barcodes\" data-toc-modified-id=\"Filter-chimeras,-assign-viral-barcodes-1.6.3\">Filter chimeras, assign viral barcodes</a></span></li></ul></li><li><span><a href=\"#Examine-10X-cell-barcodes-/-UMIs\" data-toc-modified-id=\"Examine-10X-cell-barcodes-/-UMIs-1.7\">Examine 10X cell barcodes / UMIs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-valid-cell-barcodes\" data-toc-modified-id=\"Get-valid-cell-barcodes-1.7.1\">Get valid cell barcodes</a></span></li><li><span><a href=\"#Filter-alignments-from-valid-cells\" data-toc-modified-id=\"Filter-alignments-from-valid-cells-1.7.2\">Filter alignments from valid cells</a></span></li><li><span><a href=\"#Per-gene-barcodes-/-UMI-sampling\" data-toc-modified-id=\"Per-gene-barcodes-/-UMI-sampling-1.7.3\">Per-gene barcodes / UMI sampling</a></span></li><li><span><a href=\"#Genes-sequenced-per-cell\" data-toc-modified-id=\"Genes-sequenced-per-cell-1.7.4\">Genes sequenced per cell</a></span></li></ul></li><li><span><a href=\"#Call-mutations\" data-toc-modified-id=\"Call-mutations-1.8\">Call mutations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-mutations-per-gene\" data-toc-modified-id=\"Number-of-mutations-per-gene-1.8.1\">Number of mutations per gene</a></span></li><li><span><a href=\"#Lengths-of-indels\" data-toc-modified-id=\"Lengths-of-indels-1.8.2\">Lengths of indels</a></span></li><li><span><a href=\"#Accuracy-of-mutations\" data-toc-modified-id=\"Accuracy-of-mutations-1.8.3\">Accuracy of mutations</a></span></li></ul></li><li><span><a href=\"#Analyze-flu-sequences-at-cell-level\" data-toc-modified-id=\"Analyze-flu-sequences-at-cell-level-1.9\">Analyze flu sequences at cell level</a></span><ul class=\"toc-item\"><li><span><a href=\"#Aggregate-data-at-the-cell-level\" data-toc-modified-id=\"Aggregate-data-at-the-cell-level-1.9.1\">Aggregate data at the cell level</a></span></li><li><span><a href=\"#Genes-sequenced-per-cell\" data-toc-modified-id=\"Genes-sequenced-per-cell-1.9.2\">Genes sequenced per cell</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of full-length PacBio sequencing of influenza mRNAs\n",
    "The material from the 10X libraries for the *IFN_enriched* sample was enriched for viral mRNAs by semi-specific PCR, and then sequenced by PacBio.\n",
    "Here we analyze those data.\n",
    "\n",
    "## Set up for analysis\n",
    "First, we do some things to set up this Jupyter notebook.\n",
    "\n",
    "### Import Python modules\n",
    "We import the Python modules used.\n",
    "\n",
    "We make extensive use of [dms_tools2](https://jbloomlab.github.io/dms_tools2/) to handle the PacBio data.\n",
    "\n",
    "We import [plotnine](https://plotnine.readthedocs.io/en/latest/) for plotting using a ggplot2-like syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dms_tools2 version 2.3.dev0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import subprocess\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import collections\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from IPython.display import display, HTML, Image\n",
    "import Bio.SeqIO\n",
    "\n",
    "# import plotnine for ggplot2 style plotting\n",
    "from plotnine import *\n",
    "_ = theme_set(theme_bw(base_size=12))\n",
    "\n",
    "import dms_tools2\n",
    "print(\"Using dms_tools2 version {0}\".format(dms_tools2.__version__))\n",
    "from dms_tools2.ipython_utils import showPDF\n",
    "from dms_tools2.plot import COLOR_BLIND_PALETTE_GRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define / create directories\n",
    "We define the names of key directories for input and output, and create these directories if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top results directory\n",
    "resultsdir = './results/'\n",
    "\n",
    "# directory for PacBio results\n",
    "pacbioresultsdir = os.path.join(resultsdir, 'pacbio')\n",
    "os.makedirs(pacbioresultsdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many CPUs to use\n",
    "Specify max number to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cpus = 16 # max number of CPUs to use\n",
    "ncpus = max(multiprocessing.cpu_count(), max_cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CCSs \n",
    "We build the circular consensus sequences (CCSs) using the PacBio software.\n",
    "\n",
    "### Get subreads files \n",
    "We have multiple sequencing runs:\n",
    "  - A run from June-8-2017 done at the UW PacBio core. This run used a PacBio RSII machine.\n",
    "  - A run from December-7-2017 done at the Fred Hutch Genomics core. This run used a PacBio Sequel machine.\n",
    "  \n",
    "Note that the material sequenced for these two runs was **not** identical. \n",
    "The balance of genes that were mixed differed, as well as the size selection and the way that the libraries were loaded.\n",
    "Therefore, we do not expect the same balance of different reads in the two runs.\n",
    "\n",
    "In addition, the data were processed differently.\n",
    "For the Hutch Genomics Core runs, the data are already processed into a `*.subreads.bam` file, while for UW PacBio core runs it is still in the `*.bas.h5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqruns = ['2017-06-08', '2017-12-07', '2018-06-22_nonPol', '2018-06-22_Pol-1',\n",
    "           '2018-06-22_Pol-2', '2018-06-22_Pol_open_sizesel']\n",
    "\n",
    "baseseqdir = '/fh/fast/bloom_j/SR/ngs/' # all sequencing data here\n",
    "seqdirs = {\n",
    "        '2017-06-08':os.path.join(baseseqdir, \n",
    "            'pacbio_UW/170608 Pacbio single cell/Emulsion Reaction/ABR_C_MACS.AR_0kb'),\n",
    "        '2017-12-07':os.path.join(baseseqdir,\n",
    "            'pacbio/171207_bloom_j/r54228_20171201_171054/1_A01'),\n",
    "        '2018-06-22_nonPol':os.path.join(baseseqdir,\n",
    "            'pacbio/180622_bloom_j/r54228_20180622_194519/1_A01'),\n",
    "        '2018-06-22_Pol-1':os.path.join(baseseqdir,\n",
    "            'pacbio/180622_bloom_j/r54228_20180622_194519/2_B01'),\n",
    "        '2018-06-22_Pol-2':os.path.join(baseseqdir,\n",
    "            'pacbio/180622_bloom_j/r54228_20180622_194519/3_C01'),\n",
    "        '2018-06-22_Pol_open_sizesel':os.path.join(baseseqdir,\n",
    "            'pacbio/180622_bloom_j/r54228_20180622_194519/4_D01'),\n",
    "        }\n",
    "assert set(seqruns) == set(seqdirs.keys())\n",
    "\n",
    "bam_already = collections.defaultdict(lambda: True)\n",
    "bam_already['2017-06-08'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the `*.subreads.bam` file for each run.\n",
    "If they already exist (e.g., if data were returned by the Fred Hutch Genomics Core), we just need to get the name of the file.\n",
    "But if they don't exist (e.g., if data were returned from UW PacBio Core), we need to run the PacBio [bax2bam](https://github.com/PacificBiosciences/bax2bam) software to create the `*subreads.bam` files from the `*.bas.h5` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put or copy subreads into this directory\n",
    "subreadsdir = os.path.join(pacbioresultsdir, 'subreads')\n",
    "os.makedirs(subreadsdir, exist_ok=True)\n",
    "\n",
    "# store name of subreads files for each sequencing run\n",
    "subreads = dict([(seqrun, os.path.join(subreadsdir, seqrun + '.subreads.bam'))\n",
    "                 for seqrun in seqruns])\n",
    "\n",
    "# get subreads files\n",
    "for (seqrun, subreadsfile) in subreads.items():\n",
    "    print(\"\\nGetting subreads for {0} sequencing run\".format(seqrun))\n",
    "    \n",
    "    if os.path.isfile(subreadsfile):\n",
    "        print(\"Subreads file already exists: {0}\".format(subreadsfile))\n",
    "    \n",
    "    elif bam_already[seqrun]:\n",
    "        print(\"Looking for existing subreads file...\")\n",
    "        filepattern = os.path.join(seqdirs[seqrun], '*.subreads.bam')\n",
    "        existingfiles = glob.glob(filepattern)\n",
    "        assert existingfiles, \"No file matching expected pattern of {0}\".format(filepattern)\n",
    "        assert len(existingfiles) == 1, \"Expected one file, but found multiple:\\n{0}\".format(\n",
    "                '\\n'.join(existingfiles))\n",
    "        print(\"Copying subreads file {0} to {1}...\".format(existingfiles[0], subreadsfile))\n",
    "        shutil.copy(existingfiles[0], subreadsfile)\n",
    "        shutil.copy(existingfiles[0] + '.pbi', subreadsfile + '.pbi')\n",
    "        print(\"Completed copying file.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Building subreads using `bax2bam` version {0}\".format(\n",
    "                subprocess.check_output(['bax2bam', '--version']).decode('utf-8').strip()))\n",
    "        baxfiles = []\n",
    "        for (dpath, dirnames, fnames) in os.walk(seqdirs[seqrun]):\n",
    "            baxfiles += [os.path.join(dpath, fname) for fname in fnames if fname.endswith('.bax.h5')] \n",
    "        assert len(baxfiles) > 0, \"found no `*.bax.h5` files\"\n",
    "        print(\"Will build subreads from the following `*.bax.h5` files:\\n\\t{0}\".format(\n",
    "                '\\n\\t'.join(baxfiles)))\n",
    "        print(\"Now running `bax2bam`...\")\n",
    "        ! bax2bam \\\n",
    "                {' '.join(['\"' + x + '\"' for x in baxfiles])} \\\n",
    "                -o {subreadsfile.replace('.subreads.bam', '')} \\\n",
    "                --subread\n",
    "        print(\"Completed running `bax2bam` to create {0}\".format(subreadsfile))\n",
    "        assert os.path.isfile(subreadsfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run `ccs`\n",
    "We build CCS's using PacBio's algorithm as implemented in the [ccs program](https://github.com/PacificBiosciences/unanimity/blob/develop/doc/PBCCS.md).\n",
    "\n",
    "We only want reasonably high-quality CCSs.\n",
    "The [ccs program](https://github.com/PacificBiosciences/unanimity/blob/master/doc/PBCCS.md) provides two ways to control the \"accuracy\" of reads.\n",
    "The first is the `--minPasses` option, which corresponds to how many subreads we require to call a circular consensus sequence.\n",
    "The second is the `--minPredictedAccuracy` option, which provides an explicit estimate of the accuracy.\n",
    "We will further post-process the CCSs, so we set reasonably high but not extremely stringent values: 3 passes, and at least 99.9% accuracy.\n",
    "\n",
    "We read each set of results into ` dms_tools2.pacbio.CCS` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccsdir = os.path.join(pacbioresultsdir, 'ccs')\n",
    "os.makedirs(ccsdir, exist_ok=True)\n",
    "\n",
    "ccslist = []\n",
    "for (seqrun, subreadsfile) in subreads.items():\n",
    "    print(\"\\nRunning `ccs` for sequencing run {0}\".format(seqrun))\n",
    "        \n",
    "    reportfile = os.path.join(ccsdir, seqrun + '_report.csv')\n",
    "    bamfile = os.path.join(ccsdir, seqrun + '_ccs.bam')\n",
    "    logfile = os.path.join(ccsdir, seqrun + '_log.txt')\n",
    "        \n",
    "    if all(map(os.path.isfile, [reportfile, bamfile])):\n",
    "        print(\"The `ccs` output already exists, so using that existing output.\")\n",
    "    else:  \n",
    "        print(\"Running {0}...\".format(\n",
    "                subprocess.check_output(['ccs', '--version']).decode(\n",
    "                'utf-8').strip()))\n",
    "        ! ccs \\\n",
    "            --minLength 100 \\\n",
    "            --maxLength 5000 \\\n",
    "            --minPasses 3 \\\n",
    "            --minPredictedAccuracy 0.999 \\\n",
    "            --logFile {logfile} \\\n",
    "            --reportFile {reportfile} \\\n",
    "            --polish \\\n",
    "            --numThreads {ncpus} \\\n",
    "            {subreadsfile} \\\n",
    "            {bamfile}\n",
    "        print(\"Completed `ccs` run.\")\n",
    "        \n",
    "    ccslist.append(dms_tools2.pacbio.CCS(seqrun, bamfile, reportfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of CCSs\n",
    "Now we summarize the results on the number of CCSs successfully created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmw_plot = os.path.join(ccsdir, 'ZMW_plot.pdf')\n",
    "showPDF(zmw_plot)\n",
    "\n",
    "ccs_report = dms_tools2.pacbio.summarizeCCSreports(\n",
    "                ccslist, 'zmw', zmw_plot)\n",
    "display(HTML(ccs_report.query('fraction > 0.005').to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCS accuracy / length\n",
    "Now we plot the distributions of lengths, accuracies, and number of passes for the CCSs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_plots = []\n",
    "for ccs in ccslist:\n",
    "    ccs_plot = os.path.join(ccsdir, '{0}_ccs_plot.pdf'.format(ccs.samplename))\n",
    "    dms_tools2.plot.plotColCorrs(ccs.df, ccs_plot,\n",
    "            ['passes', 'CCS_accuracy', 'CCS_length'], title=ccs.samplename)\n",
    "    ccs_plots.append(ccs_plot)\n",
    "showPDF(ccs_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align CCSs to flu genes\n",
    "The PacBio sequencing was performed on PCR-amplified product.\n",
    "This PCR product was amplified off the 10X barcoded material using semi-specific PCR with one end specifically annealing to flu transcripts.\n",
    "We want to identify the CCS's that represent properly barcoded 10X material from influenza genes, and then call the barcodes and align the barcoded mRNA to influenza transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcoded CCS features\n",
    "This [10X technical note](https://teichlab.github.io/scg_lib_structs/data/CG000108_AssayConfiguration_SC3v2.pdf) outlines the sequences appended by the v2 10X single-cell 3' kit used in these experiments. \n",
    "Specifically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image('./data/images/10xschematic.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming in on the 3' adaptor sequence, it is:\n",
    "`CTACACGACGCTCTTCCGATCT-NNNNNNNNNNNNNNNN-NNNNNNNNNN-TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTVN` where the dash-delimited sequences are the read-1 priming site, the 16XN cell barcode, the 10XN UMI, the 30XT oligo-dT primer, followed by `V` (anything but `T`) and `N` (nominally, first nucleotide of upstream of mRNA polyA tail).\n",
    "\n",
    "For the PCR to enrich the 10X product, Alistair used a 3' primer that anneals to this adaptor, namely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primer3 = 'CTACACGACGCTCTTCCGATCT'\n",
    "print(\"The length of the 3' primer is {0} nt\".format(len(primer3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 5' primer, Alistair used a mix of primers that covered each of the 8 flu gene segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primer5_mix = {'PB2':'GCGAAAGCAGGTCAATTATATTCAATATGGAAAG',\n",
    "               'PB1':'GCGAAAGCAGGCAAACCATTTG',\n",
    "               'PA':'GCGAAAGCAGGTACTGATTCAAAATGG',\n",
    "               'HA':'GCAAAAGCAGGGGAAAATAAAAACAACC',\n",
    "               'NP':'GCAAAAGCAGGGTAGATAATCACTCAC',\n",
    "               'NA':'GCGAAAGCAGGAGTTTAAATGAATCCAAAC',\n",
    "               'M':'GCAAAAGCAGGTAGATATTGAAAGATGAGTC',\n",
    "               'NS':'GCAAAAGCAGGGTGACAAAGACATAATG',\n",
    "              }\n",
    "print(\"The length of the 5' primer ranges from {0} to {1} nt\".format(\n",
    "        min(map(len, primer5_mix.values())), max(map(len, primer5_mix.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flu alignment targets\n",
    "We want to align the barcoded sequences to the flu mRNAs.\n",
    "We will align to the wildtype flu sequences using a `dms_tools2.minimap2.Mapper`, and then call the synonymous barcodes using a `dms_tools2.minimap2.TargetVariants` object.\n",
    "Both of these objects are initialized here.\n",
    "\n",
    "The wildtype flu mRNA sequences are in [./data/flu_sequences/flu-wsn-mRNA.fasta](./data/flu_sequences/flu-wsn-mRNA.fasta), and the synonymous barcoded ones are in [./data/flu_sequences/flu-wsn-mRNA-double-syn.fasta](./data/flu_sequences/flu-wsn-mRNA-double-syn.fasta).\n",
    "We want to align to the sequence **interior** to the primer binding sites defined above: the region between the custom 5' primer and the polyA tail.\n",
    "We therefore read in the mRNAs, and then trim each from the 5' termini to the end of the primer binding site, and then write these to a file to use as the alignment targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the targets and synonymous-barcoded targets mRNAs\n",
    "targets = collections.defaultdict(list)\n",
    "for variant in ['', '-double-syn']:\n",
    "    for full_mRNA in Bio.SeqIO.parse(\n",
    "            './data/flu_sequences/flu-wsn{0}-mRNA.fasta'.format(variant), 'fasta'):\n",
    "        full_mRNA_seq = str(full_mRNA.seq)\n",
    "        primer = [p for p in primer5_mix.values() if full_mRNA_seq.count(p)]\n",
    "        assert len(primer) == 1, \"matched multiple primers in {0}\".format(full_mRNA.name)\n",
    "        targetseq = full_mRNA_seq[full_mRNA_seq.index(primer[0]) + len(primer[0]) : ]\n",
    "        targets[variant].append((full_mRNA.name, targetseq))\n",
    "        if not variant:\n",
    "            print(\"Aligning to {0} nt region of {1}\".format(len(targetseq), full_mRNA.name))\n",
    "\n",
    "# write the targets to files\n",
    "aligndir = os.path.join(pacbioresultsdir, 'alignments')\n",
    "os.makedirs(aligndir, exist_ok=True)\n",
    "targetfile = os.path.join(aligndir, 'targets.fasta')\n",
    "with open(targetfile, 'w') as f:\n",
    "    f.write('\\n'.join('>{0}\\n{1}'.format(*tup) for tup in targets['']))\n",
    "syntargetfile = os.path.join(aligndir, 'targets-double-syn.fasta')\n",
    "with open(syntargetfile, 'w') as f:\n",
    "    f.write('\\n'.join('>{0}\\n{1}'.format(*tup) for tup in targets['-double-syn']))\n",
    "\n",
    "# initialize mapper\n",
    "mapper = dms_tools2.minimap2.Mapper(targetfile,\n",
    "        dms_tools2.minimap2.OPTIONS_VIRUS_W_DEL,\n",
    "        target_isoforms={'fluM1':['fluM2'], 'fluM2':['fluM1'],\n",
    "                         'fluNS1':['fluNS2'], 'fluNS2':['fluNS1']})\n",
    "print(\"\\nPerforming alignments with minimap2 version {0}\".format(mapper.version))\n",
    "\n",
    "# initialize target variant caller\n",
    "targetvariants = dms_tools2.minimap2.TargetVariants({'wildtype':targetfile,\n",
    "        'synonymously barcoded':syntargetfile}, mapper, variantsites_min_acc=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match and align CCSs\n",
    "We use the function `dms_tools2.pacbio.matchAndAlignCCS` to go through the CCS's, find the ones that are \"barcoded\" (have the proper elements), and the align these barcoded genes.\n",
    "All the results go into a pandas data frame called *df_ccs*.\n",
    "\n",
    "Specifically, we look for CCS's that have:\n",
    "  - Any 5' primer from Alistair's mix, trimmed a bit at the start since the first few nucleotides in the CCS might be off. We call this *termini5*.\n",
    "  - The mRNA itself, which we call the *gene*. Since we define the polyA tail as beginning on the first `A` at the polyA signal, the gene must end on a non-`A` nucleotide (which is the IUPAC code `B`).\n",
    "  - The polyA tail, which is effectively a spacer between the *gene* and the *UMI* / *barcode*. This tail is expected to be 30 `A`'s from 10X primer, but we allow it to be anything greater than 25 to account for the sloppiness in sequencing and primer synthesis associated with runs. We also use [regex fuzzy matching](https://stackoverflow.com/a/15975649) to allow the polyA to have up to two non-`A` nucleotides internal to it, since for instance the `VN` tooth in the oligo-dT primer might sometimes anneal in the wrong spot. We call this the *spacer* in the call to `dms_tools2.pacbio.matchAndAlignCCS`, but then rename to *polyA*.\n",
    "  - The 10-nucleotide UMI from the 10X primer, which we call *UMI*.\n",
    "  - The 16-nucleotide cell barcode from the 10X primer, which we call *barcode*.\n",
    "  - The 3' primer that Alistair used, which anneals in the read 1 primer binding site on the 10X primer. We call this *termini3*.\n",
    "  \n",
    "Note also that in the call to `dms_tools2.pacbio.matchAndAlignCCS`, we specify that *M1* and *M2* are isoforms, and *NS1* and *NS2* are isoforms.\n",
    "  \n",
    "We don't require a match to the first 5 nt of each termini, as sometimes the ends of the CCS's can be \"sloppy\".\n",
    "\n",
    "We use a `dms_tools2.minimap2.MutationCaller` to call mutations.\n",
    "This calling is done in 1-based indexing of the target, and uses modest clipping of the target and soft clipping of the query to avoid calling mutations right at the ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_ends = 5 # trim this many off each termini\n",
    "\n",
    "mutationcaller = dms_tools2.minimap2.MutationCaller(\n",
    "        query_softclip=10, target_clip=20)\n",
    "\n",
    "df_ccs = dms_tools2.pacbio.matchAndAlignCCS(\n",
    "        ccslist=ccslist,\n",
    "        mapper=mapper,\n",
    "        termini5='|'.join([s[trim_ends : ] for s in primer5_mix.values()]),\n",
    "        gene='N+B',\n",
    "        spacer='AAA(A{19,}){e<=2}AAA', # regex fuzzy matching allows 2 mismatch\n",
    "        umi='N{10}',\n",
    "        barcode='N{16}',\n",
    "        termini3=dms_tools2.utils.reverseComplement(primer3)[ : trim_ends],\n",
    "        targetvariants=targetvariants,\n",
    "        mutationcaller=mutationcaller\n",
    "        ).rename(columns={'has_spacer':'has_polyA'})\n",
    "\n",
    "print(\"Attempted to match and align all {0} CCSs\".format(len(df_ccs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats on matching / alignment\n",
    "Below we analyze the statistics on the matching and aligning of the CCSs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible matching / alignment categories\n",
    "match_align_cats = ['total', 'has_termini3', 'has_polyA', 'has_termini5',\n",
    "                    'barcoded', 'gene_aligned', 'CCS_aligned']\n",
    "\n",
    "# tabulate statistics on matching / alignment\n",
    "match_align_df = (\n",
    "    df_ccs\n",
    "    .assign(total=True)\n",
    "    .melt(id_vars=['samplename'], \n",
    "          value_vars=match_align_cats,\n",
    "          var_name='category',\n",
    "          value_name='number of CCSs')\n",
    "    .groupby(['samplename', 'category'], as_index=False)\n",
    "    .aggregate('sum')\n",
    "    .assign(category=lambda x: pandas.Categorical(\n",
    "            x.category.str.replace('_', ' '), \n",
    "            [col.replace('_', ' ') for col in match_align_cats]))\n",
    "    .sort_values(['samplename', 'category'])\n",
    "    .assign(percent=lambda x: 100 * x['number of CCSs'] / \n",
    "               x.groupby('samplename')['number of CCSs'].transform('max'))\n",
    "    )\n",
    "print(\"Here is a table of the matching / alignment statistics:\")\n",
    "display(HTML(match_align_df.to_html(index=False, float_format='%d')))\n",
    "\n",
    "# plot the matching alignment statistics\n",
    "match_align_plot = os.path.join(aligndir, 'match_align_plot.pdf')\n",
    "(ggplot(match_align_df, aes('samplename', 'number of CCSs')) +\n",
    "    geom_bar(aes(fill='category'), position='dodge', stat='identity') +\n",
    "    scale_fill_manual(COLOR_BLIND_PALETTE_GRAY) +\n",
    "    xlab('sequencing run') \n",
    "    ).save(match_align_plot,\n",
    "           width=1.5 * (1 + len(seqruns)),\n",
    "           height=3)\n",
    "print(\"\\nHere is a plot of the results:\")\n",
    "showPDF(match_align_plot, width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that across both samples, the vast majority of CCSs have the 3' termini and the polyA, as might be expected given that those need to be there for the 3' primer to work.\n",
    "\n",
    "However, only a bit over 20% have the 5' termini.\n",
    "This could be because only a small fraction of all sequences in the initial PCR template pool will be flu mRNAs with the right termini for the 5' primer, so there may be spurious amplification (by the 3' primer or just linear amplification product) that doesn't have the 5' termini.\n",
    "\n",
    "Most of the CCSs that have the 5' termini are also *barcoded* in the sense that they fully match the expected patterns that allow us to call a barcode and UMI.\n",
    "\n",
    "Of these *barcoded* CCSs, most of them have mRNA inserts (\"genes\") that align to the flu targets, and so are in the *gene aligned* category.\n",
    "\n",
    "We also see that if we align the full CCS without requiring it to match the termini / barcode / polyA, we get a few more than for the *gene aligned* category, indicating that some of the CCSs for which we can't call barcodes still have flu in them.\n",
    "These may have mutations in the termini / polyA, or they may be some sort of chimera.\n",
    "In any case, since the *CCS aligned* category is only modestly larger than the *gene aligned* category, for all subsequent analyses we'll focus just on the *gene aligned* CCSs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CCSs with gene aligned\n",
    "For the reasons explained immediately above, all remaining analyses will focus only on the CCSs in the *gene aligned* category.\n",
    "So only keep these in our *df_ccs* data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccs = df_ccs.query('gene_aligned').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality-control alignments\n",
    "For the CCSs for which the gene insert aligned to flu, we now do some quality controlling on several important aspects.\n",
    "\n",
    "We do this by adding a column to our data frame named `QC_filtered`.\n",
    "Initially all entries in this columns are the string \"passes_filters\".\n",
    "As we go through each filter in order below, we add a string describing the filtering reason for each CCS that fails that filter.\n",
    "Once a CCS fails one filter (in the order they are provided below), we don't continue checking it against the other filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccs['pass_QC'] = True\n",
    "df_ccs['QC_fail_reason'] = 'passes_QC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcode accuracy\n",
    "We want the barcodes called in the CCSs to be high accuracy. \n",
    "This might not be the case if molecules with different barcodes anneal during the PCR, such that a different barcode is sequenced on each strand of the SMRTbell that forms the CCS.\n",
    "So we tabulate some statistics about the distribution of barcode accuracies among CCSs that pass our filters so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ccs\n",
    "    .query('pass_QC')\n",
    "    .groupby('samplename')\n",
    "    .barcode_accuracy\n",
    "    .describe(percentiles=[0.001, 0.01, 0.02])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see that the barcode accuracies are consistently very high, with over 98% having accuracies that exceed the accuracy threshold of 0.999 used when building the CCSs with PacBio's [ccs program](https://github.com/PacificBiosciences/unanimity/blob/develop/doc/PBCCS.md), and all of them having accuracies of >96%.\n",
    "Just to be safe, we will filter for CCSs that have a barcode accuracy $\\ge$0.999, which will eliminate only a very small fraction.\n",
    "\n",
    "We not in the data frame which of the CCSs that have not already been filtered fail this barcode accuracy filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_index = df_ccs.query('pass_QC & (barcode_accuracy < 0.999)').index\n",
    "df_ccs.loc[fail_index, 'pass_QC'] = False\n",
    "df_ccs.loc[fail_index, 'QC_fail_reason'] = 'low barcode accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional alignments\n",
    "We want to get rid of CCSs that align to multiple different influenza genes.\n",
    "The reason is that these probably represent some sort of PCR chimera / fusion during the library preparation.\n",
    "Note that we are only looking at multiple alignments to different targets / isoforms (we specified that M1 / M2 and NS1 / NS2 are isoforms in the `target_isoforms` argument to the `dms_tools2.minimap2.Mapper`), so this will not purge alignments that involve the same gene (these could be complex deletions) or different splice forms.\n",
    "First, we tabulate some statistics about the distribution of the number of additional alignments to different targets among CCSs that pass our filters so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ccs\n",
    "    .query('pass_QC')\n",
    "    .groupby('samplename')\n",
    "    .gene_aligned_n_additional_difftarget\n",
    "    .describe(percentiles=[0.99, 0.999, 0.9999])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few CCSs with additional alignments to other targets (less than 1%), and we remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_index = df_ccs.query('pass_QC & gene_aligned_n_additional_difftarget').index\n",
    "df_ccs.loc[fail_index, 'pass_QC'] = False\n",
    "df_ccs.loc[fail_index, 'QC_fail_reason'] = 'aligns to multiple targets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excessive alignment trimming\n",
    "For perfect matches the of query CCSs to the target flu mRNAs, alignment of the query to the target is end-to-end, with no trimming of either the query or the target at either end.\n",
    "\n",
    "However, in practice, in many cases there is trimming of the query or the target.\n",
    "Here we QC filter based on the presence of excessive trimming.\n",
    "\n",
    "#### Trimming of query start\n",
    "Based on the way that the products were PCR-amplified, we expect the query starts to align exactly with the target start, so there shouldn't be any need for trimming.\n",
    "Below are tabulated statistics about the distribution of trimming at the query start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ccs\n",
    "    .query('pass_QC')\n",
    "    .groupby('samplename')\n",
    "    .gene_aligned_n_trimmed_query_start\n",
    "    .describe(percentiles=[0.99, 0.999, 0.9999])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most (>99%) queries align exactly with the target at their start, with no trimming. \n",
    "There are a few nucleotides trimmed from a modest fraction (<1%).\n",
    "This modest trimming is explainable---the 5' primers are similar for the different flu genes, so there may occassionally be mis-priming so that the primer amplifies a different flu mRNA, which might lead to a bit of trimming at the very start of the alignment.\n",
    "There are then a very small number (less than <0.01%) that have very large amounts trimmed.\n",
    "We will discard CCSs with more than 5 nucleotides trimmed from the query start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_index = df_ccs.query('pass_QC & (gene_aligned_n_trimmed_query_start > 5)').index\n",
    "df_ccs.loc[fail_index, 'pass_QC'] = False\n",
    "df_ccs.loc[fail_index, 'QC_fail_reason'] = 'excessive trimming of query start'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trimming of target start\n",
    "We also expect all of the alignments to start exactly at the begin of the target, because the PCR-amplification should lead to this.\n",
    "Below are tabulated statistics about the distribution of trimming at the target start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ccs\n",
    "    .query('pass_QC')\n",
    "    .groupby('samplename')\n",
    "    .gene_aligned_n_trimmed_target_start\n",
    "    .describe(percentiles=[0.99, 0.999, 0.9999])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution looks very similar to that for trimming of the query starts immediately above, and (for the same logic explained there), we will discard CCSs with more than 5 nucleotides trimmed from the target start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_index = df_ccs.query('pass_QC & (gene_aligned_n_trimmed_target_start > 5)').index\n",
    "df_ccs.loc[fail_index, 'pass_QC'] = False\n",
    "df_ccs.loc[fail_index, 'QC_fail_reason'] = 'excessive trimming of target start'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trimming query ends\n",
    "We expect the queries to end at the end of the target, and so there to be no clipping of the query ends. \n",
    "There are three plausible reasons for clipping of the query ends:\n",
    "  1. A PCR artifact that leads to fusion of a flu gene with a cellular gene. We tried to filter out fusions of two different flu genes above by removing CCSs with additional alignments to a different flu target, but that filter won't remove fusions to things that aren't flu genes--although these are expected to be much more abundant. We would like to filter CCSs for which this occurs.\n",
    "  2. The transcription of the mRNA from the query continuing past the polyA tail, or the polyA tail not be fully trimmed and removed. We might want to retain these. However, we expect the extension that has tobe trimmed in this case to be small, probably less than 50 nt.\n",
    "  3. There is an internal deletion and for whatever reason the mapping failed to handle it properly and just trimmed the region after the deletion. We want to keep these. We would expect them to align with \"additional alignments\" since the trimmed region should be in a different alignment.\n",
    "  \n",
    "Below we tabulate some statistics on the distribution of trimming, for CCSs both with and without additional alignments (these distributions are hard to plot since they are so skewed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ccs\n",
    "    .query('pass_QC')\n",
    "    .assign(has_additional_alignment=lambda x: x.gene_aligned_n_additional > 0)\n",
    "    .groupby(['samplename', 'has_additional_alignment'])\n",
    "    .gene_aligned_n_trimmed_query_end\n",
    "    .describe(percentiles=[0.9, 0.95, 0.98, 0.99, 0.999])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the distributions don't look much different between CCSs with and without additional alignments, so the internal deletion explanation doesn't appear to explain most of the clipping.\n",
    "We will discard CCSs with more than 50 nt of trimming at the query end as almost certainly spurious, but keep those with less than 50 nt in case there is transcription past the polyA and/or problems calling the polyA.\n",
    "Looking at the table above, we can see that this means we are discarding about 5% of the CCSs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_index = df_ccs.query('pass_QC & (gene_aligned_n_trimmed_query_end > 50)').index\n",
    "df_ccs.loc[fail_index, 'pass_QC'] = False\n",
    "df_ccs.loc[fail_index, 'QC_fail_reason'] = 'excessive trimming of query end'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trimming target ends\n",
    "If transcription proceeds all the way to the target end, there should also not be trimming of the target ends.\n",
    "Here are some actual tabulated statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ccs\n",
    "    .query('pass_QC')\n",
    "    .groupby('samplename')\n",
    "    .gene_aligned_n_trimmed_target_end\n",
    "    .describe(percentiles=[0.9, 0.95, 0.98, 0.99, 0.999])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in reality there is quite a bit of trimming of the target ends in 5-10% of CCSs.\n",
    "However, there is a legitimate possible explanation: premature poly-adenylation of the flu transcripts leading to truncation of the query, or some form of internal deletion in the vRNA moving the polyA signal up in the transcript.\n",
    "Since both of these seem plausible, for now we do not do any filtering based on the trimming of the target ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get QC-ed alignments\n",
    "Now we tabulate the number of alignments that failed QC for each reason:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_ccs\n",
    "    .assign(number=1)\n",
    "    .groupby(['samplename', 'pass_QC', 'QC_fail_reason'])\n",
    "    [['number']]\n",
    "    .agg('count')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the table above shows, less than 10% of the alignments fail the filters, and most of the failures are due to excessive trimming of the query end.\n",
    "\n",
    "We keep just the QC-ed aligned CCSs for subsequent work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccs = df_ccs.query('pass_QC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of QC-ed alignments\n",
    "We are now going to analyze how many QC-ed alignments we have for each gene, and the length distribution of these alignments.\n",
    "\n",
    "First, make the aligned genes a categorical variable so gene names are displayed in the desired order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetnames = list(mapper.targetseqs.keys())\n",
    "df_ccs.gene_aligned_target = pandas.Categorical(\n",
    "        df_ccs.gene_aligned_target, targetnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of alignments per gene\n",
    "Now we examine the number of QC-ed aligned CCSs for each gene.\n",
    "We do this both aggregating over all sequencing runs and looking at the runs individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base plot of number of sequences per gene\n",
    "plot_nseqs = (\n",
    "    ggplot(df_ccs, aes('gene_aligned_target')) +\n",
    "        geom_bar() +\n",
    "        theme(axis_text_x=element_text(angle=90, hjust=0.5)) +\n",
    "        xlab(\"flu gene\") +\n",
    "        ylab(\"QC-ed aligned sequences\")\n",
    "    )\n",
    "\n",
    "# plot total for all runs and by run\n",
    "for plottype, facet, n in [\n",
    "        ('all_runs', geom_blank(), 1),\n",
    "        ('by_run', facet_wrap('~samplename'), len(seqruns))]:\n",
    "    print(\"\\nNumber of alignments, {0}:\".format(plottype.replace('_', ' ')))\n",
    "    nseqs_plot = os.path.join(aligndir, 'nsequences_{0}.pdf'.format(plottype))\n",
    "    (plot_nseqs + facet).save(nseqs_plot, height=2.5, width=0.8 + 2 * n)\n",
    "    showPDF(nseqs_plot, width=80 + 200 * n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above show that in total we have many more alignments for the polymerase genes, mostly due to the 2017-12-07 run being highly biased towards these genes.\n",
    "This is because whereas the first run tried to amplify everything equally, the second run overloaded PB2 / PB1 / PA because they were much rarer in the first run.\n",
    "But see the caveat about deletions that becomes apparent below...\n",
    "\n",
    "Also, we see that there are many fewer alignments for M2 than M1, and for NS2 than NS1. \n",
    "This is as expected based on the known ratios of these splice forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of alignment lengths\n",
    "Not all of the alignments necessarily cover the entire gene, as there are often deletions in flu segments and can in principle also be insertions.\n",
    "So we also plot the distribution of alignments by length for each segment, where we define the *alignment length* as the total number of aligned nucleotides, which can be either identities or mismatches (but not indels).\n",
    "Note that each subplot below is shown with **its own y-axis**, so the plots show the distribution of lengths within each gene / sequencing run, but not the relative numbers of alignments across them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columnn with alignment lengths\n",
    "df_ccs['alignment_length'] = df_ccs.gene_aligned_cigar.apply(\n",
    "        dms_tools2.minimap2.numAligned)\n",
    "\n",
    "# base plot of alignment lengths\n",
    "plot_align_len = (\n",
    "    ggplot(df_ccs, aes('alignment_length')) +\n",
    "        geom_histogram(aes(x='alignment_length', y='..density..'), bins=15) +\n",
    "        theme(axis_text_x=element_text(angle=90, hjust=0.5),\n",
    "              axis_text_y=element_blank(), axis_ticks=element_blank()) +\n",
    "        ylab(\"relative number of alignments\") +\n",
    "        xlab(\"alignment length\")\n",
    "        )\n",
    "\n",
    "# plot for all runs and by run\n",
    "for plottype, facet, n in [\n",
    "        ('all_runs', facet_wrap('~ gene_aligned_target', nrow=1), 1),\n",
    "        ('by_run', facet_grid('samplename ~ gene_aligned_target'), len(seqruns))]:\n",
    "    print(\"\\nAlignment lengths, {0}:\".format(plottype.replace('_', ' ')))\n",
    "    align_len_plot = os.path.join(aligndir, 'alignment_len_{0}.pdf'.format(plottype))\n",
    "    (plot_align_len + facet).save(align_len_plot, width=15, height=1.7 * n)\n",
    "    showPDF(align_len_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, for most genes the alignments are strongly peaked at the length expected for the full-length gene.\n",
    "But for the polymerase genes (PB2, PB1, and PA), most of the reads are actually deletions that are much smaller than the full-length size.\n",
    "For HA, there are also prominent peaks at smaller sizes.\n",
    "\n",
    "The enrichment of deletions for the polymerase probably exceed the actual biological frequency of these, and might also be due to amplification bias that prefers shorter segments during PCR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near full-length alignments\n",
    "Given the plots above that show that for some genes, many of the alignments are for partially deleted genes, we also plot the number \"near full-length\" alignments.\n",
    "We define an alignment as \"full-length\" if the alignment length (as defined immediately above) is no more than 20 nucleotides less than the expected length of the alignment target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign target lengths and near full-length status\n",
    "target_lengths = {name:len(seq) for name, seq in mapper.targetseqs.items()}\n",
    "df_ccs = (\n",
    "    df_ccs\n",
    "    .assign(target_length=lambda x: x.gene_aligned_target.map(target_lengths))\n",
    "    .assign(full_length=lambda x: (x.target_length <= 20 + x.alignment_length))\n",
    "    )\n",
    "\n",
    "plot_nseqs_full = (\n",
    "    ggplot(df_ccs, aes('gene_aligned_target')) +\n",
    "        geom_bar(aes(fill='full_length')) +\n",
    "        theme(axis_text_x=element_text(angle=90, hjust=0.5)) +\n",
    "        xlab(\"flu gene\") +\n",
    "        ylab(\"QC-ed aligned sequences\") +\n",
    "        scale_fill_manual(COLOR_BLIND_PALETTE_GRAY[1 : ],\n",
    "                          name='full length')\n",
    "    )\n",
    "\n",
    "# plot total for all runs and by run\n",
    "for plottype, facet, n in [\n",
    "        ('all_runs', geom_blank(), 1),\n",
    "        ('by_run', facet_wrap('~samplename'), len(seqruns))]:\n",
    "    print(\"\\nNumber of alignments, {0}:\".format(plottype.replace('_', ' ')))\n",
    "    nseqs_plot = os.path.join(aligndir, 'nsequences_full_len_{0}.pdf'.format(plottype))\n",
    "    (plot_nseqs_full + facet).save(nseqs_plot, height=2.5, width=2 * (n + 0.8))\n",
    "    showPDF(nseqs_plot, width=220 * (n + 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see basically what is expected from the sets of plots in the previous two subsections.\n",
    "Although we have many alignments for the polymerase genes, these are highly biased towards short fragments.\n",
    "We have fairly good coverage of full-length segments for all other genes except the polymerase.\n",
    "Note that the we have relatively little for M2 / NS2, but these sequences are contained within the M1 / NS1, so it's probably OK to have less for these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze viral barcodes\n",
    "Each viral gene is either fully wildtype or \"doubly synonymously barcoded\" by a pair of synonymous mutations near each termini.\n",
    "Note that these viral barcodes are distinct from the cell barcodes added by the 10X system.\n",
    "These viral barcodes were called during the alignment using the `dms_tools2.minimap2.TargetVariants` initialized above.\n",
    "\n",
    "Here we examine these barcodes. \n",
    "The most important reason to do this is to test for strand exchange during PCR, or pairing of different variants into the same dsDNA molecule during library preparation.\n",
    "These would manifest as CCSs in which the different ends are assigned to different viral barcode variants, or in which the viral barcode sites are low accuracy.\n",
    "\n",
    "### Inspect viral barcodes by gene\n",
    "First we just plot the viral barcodes that are called for each gene in each sequencing run.\n",
    "This plot is below.\n",
    "In addition to faceting on sequencing run, we also facet on all QC-ed aligned sequences, and just those that correspond to full-length viral genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for the CCS analysis\n",
    "analysisdir = os.path.join(pacbioresultsdir, 'variant_and_mutation_analysis')\n",
    "os.makedirs(analysisdir, exist_ok=True)\n",
    "\n",
    "# order viral barcode categories from most to least for plotting\n",
    "viralbarcode_cats = (\n",
    "    df_ccs\n",
    "    .groupby(['gene_aligned_target_variant'])\n",
    "    .CCS\n",
    "    .agg('count')\n",
    "    .sort_values(ascending=False)\n",
    "    .index\n",
    "    )\n",
    "df_ccs['gene_aligned_target_variant'] = pandas.Categorical(\n",
    "        df_ccs['gene_aligned_target_variant'], viralbarcode_cats)\n",
    "\n",
    "viralbarcode_plot = os.path.join(analysisdir, 'viralbarcodeplot.pdf')\n",
    "(ggplot(pandas.concat([\n",
    "            df_ccs.assign(full_length='any length'),\n",
    "            df_ccs.query('full_length').assign(full_length='full length')]),\n",
    "        aes('gene_aligned_target')) +\n",
    "    geom_bar(aes(fill='gene_aligned_target_variant')) +\n",
    "    facet_grid('samplename ~ full_length', scales='free_y') +\n",
    "    scale_fill_manual(COLOR_BLIND_PALETTE_GRAY, name='viral barcode') +\n",
    "    theme(axis_text_x=element_text(angle=90, hjust=0.5), panel_spacing_x=0.5) +\n",
    "    ylab('QC-ed aligned sequences\\n') +\n",
    "    xlab('flu gene')\n",
    "    ).save(viralbarcode_plot, width=8, height=1.5 * (len(seqruns) + 0.5))\n",
    "showPDF(viralbarcode_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots look pretty good.\n",
    "The states that we really want to avoid are *mixed* barcodes (indicating chimeras) or *low accuracy* barcodes (indicating possible chimeric dsDNA during library preparation).\n",
    "These states are very rare for all genes on all sequencing runs.\n",
    "With the exception of PB2 / PB1 / PA, things look very consistent across genes and sequencing runs, with most barcodes either assigned to fully *wildtype* or fully *synonymously barcoded*.\n",
    "The *synonymously barcoded* variant is clearly more common.\n",
    "\n",
    "Things are a bit more complicated for the polymerase genes, where we can only partiall call many of the barcodes. \n",
    "This is because there are lots of internal deletions, some of which remove barcode variant sites.\n",
    "In addition, the PCR enrichment selectively favored these deletions, so there is skewing in abundance.\n",
    "But if we limit to just full-length genes, things look fairly similar for the polymerase as for other genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate rate of PCR strand exchange\n",
    "We will now use the above data to estimate the rate of PCR strand exchange.\n",
    "In principle, this rate could (and probably does to some degree) vary among molecules and sequencing runs. \n",
    "However, the plots in the previous subsection suggest that this variation is fairly small.\n",
    "So will just make a single \"average\" estimate over all the data.\n",
    "\n",
    "We make the estimate just using the counts of the full *wildtype* and *synonymously barcoded* variants, and ignore the partially barcoded ones.\n",
    "The reason that we ignore the partially barcoded ones is that they often represent calling of the barcodes at only one end of the molecule, which might not identify strand exchange.\n",
    "We consider variants to be *chimeric* if their barcoded sites are **either** *mixed* or *low accuracy*, since *low accuracy* can indicate mixed variants in the CCS seuqencing.\n",
    "\n",
    "First, we get and display these statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimera_stats = (\n",
    "    df_ccs\n",
    "    .rename(columns={'gene_aligned_target_variant':'viral_barcode'})\n",
    "    .replace({'viral_barcode':{'mixed':'chimeric', 'low accuracy':'chimeric'}})\n",
    "    .query('viral_barcode in [\"chimeric\", \"wildtype\", \"synonymously barcoded\"]')\n",
    "    .assign(number=1) # dummy variable to count in `agg`\n",
    "    .groupby('viral_barcode')\n",
    "    .agg({'number':'count'})\n",
    "    .assign(fraction=lambda x: x.number / x.number.sum())\n",
    "    )\n",
    "\n",
    "display(HTML(chimera_stats.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we don't expect to observe all the chimeric CCSs, because some will be chimeras of a wildtype with wildtype, or synonymously barcoded with synonymously barcoded.\n",
    "The amplification was done using emulsion PCR, which places each molecule in its own droplet.\n",
    "We can therefore use the equation for calculating the multiplet frequency described in [Bloom (2018, DOI 10.1101/293639)](https://doi.org/10.1101/293639).\n",
    "Below we take the function described there, and then calculate the multiplet frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multipletFreq(n1, n2, n12):\n",
    "    \"\"\"Estimated multiplet frequency from cell-type mixing experiment.\n",
    "\n",
    "    `n1`, `n2`, `n12` (`int` or `numpy.ndarray` of integers)\n",
    "        Number of droplets with at least one cell of type 1,\n",
    "        at least one cell of type 2, or cells of both types.\n",
    "    \"\"\"\n",
    "    n = numpy.array(n1 * n2 / n12).astype('float')\n",
    "    mu1 = -numpy.log((n - n1) / n)\n",
    "    mu2 = -numpy.log((n - n2) / n)\n",
    "    mu = mu1 + mu2\n",
    "    return 1 - mu * numpy.exp(-mu) / (1 - numpy.exp(-mu))\n",
    "\n",
    "print(\"The estimated rate at which CCSs are chimeric is {0:.4f}\".format(\n",
    "        multipletFreq(chimera_stats.number.ix['wildtype'],\n",
    "                      chimera_stats.number.ix['synonymously barcoded'],\n",
    "                      chimera_stats.number.ix['chimeric'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that about 5% of the molecules are estimated to be chimeras.\n",
    "Of these, about half are chimeric between different barcodes, and so can be explicitly excluded as is done in the subsection that immediately follows.\n",
    "That leaves about 2.5% of CCSs that will still be un-identified chimeras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter chimeras, assign viral barcodes\n",
    "We now remove any of the aligned CCSs with chimeric or low accuracy barcodes.\n",
    "We also assign each CCS its *viral_barcode* as *wt_flu* if it is either fully or partially wildtype barcoded, and *flu_syn* if it is either fully or partially synonymously barcoded.\n",
    "This *viral_barcode* is therefore an indication of which viral variant gave rise to this CCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstart = len(df_ccs)\n",
    "\n",
    "df_ccs = (\n",
    "    df_ccs.assign(viral_barcode=lambda x: x.gene_aligned_target_variant.str\n",
    "        .replace(re.compile('(partial ){0,1}wildtype'), 'flu_wt')\n",
    "        .replace(re.compile('(partial ){0,1}synonymously barcoded'), 'flu_syn'))\n",
    "    .query('viral_barcode in [\"flu_wt\", \"flu_syn\"]')\n",
    "    )\n",
    "\n",
    "print(\"Retained the {0} of {1} ({2:.2f}%) QC-ed aligned CCSs with valid viral barcodes.\"\n",
    "      .format(len(df_ccs), nstart, 100 * len(df_ccs) / nstart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine 10X cell barcodes / UMIs\n",
    "Now we examine the 10X cell barcodes and UMIs that were called for the aligned genes.\n",
    "Recall that the cell barcode reports which cell the sequence came from, and the UMI is a unique identifier for molecules.\n",
    "\n",
    "### Get valid cell barcodes\n",
    "Only some of the cell barcodes are actually assigned to cells that are called by the 10X `cellranger` pipeline, with the others typically being GEMs with no actual cell (or perhaps sometimes sequencing errors).\n",
    "\n",
    "We have already called the valid cells with the [align_and_annotate.ipynb](align_and_annotate.ipynb) notebook, and written them to `results/cellgenecounts/merged_humanplusflu_cells.tsv`. \n",
    "First, we read in those barcodes, filtering for the ones from the *IFN_enriched* sample and removing the suffix `-IFN_enriched` from them.\n",
    "These represent our set of *valid* cell barcodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellbarcodesfile = 'results/cellgenecounts/merged_humanplusflu_cells.tsv'\n",
    "sample = 'IFN_enriched' # only keep barcodes for this sample\n",
    "\n",
    "valid_cellbarcodes = set(\n",
    "    pandas.read_csv(cellbarcodesfile, sep='\\t')\n",
    "    .query('Sample == @sample')\n",
    "    .CellBarcode.str.replace('-' + sample, '')\n",
    "    )\n",
    "\n",
    "print(\"Read {0} valid cell barcodes for sample {1} from {2}\"\n",
    "        .format(len(valid_cellbarcodes), sample, cellbarcodesfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter alignments from valid cells\n",
    "We really only care about the alignments that correspond to valid cells, so now we filter for those.\n",
    "First, we annotate CCS alignments that correspond to a valid cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccs['valid_cell'] = df_ccs.barcode.isin(valid_cellbarcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the fraction of aligned CCSs that correspond to valid cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_cells_plots = []\n",
    "for pos, label in [('stack', 'number'), ('fill', 'fraction')]:\n",
    "    valid_cells_plot = os.path.join(analysisdir, 'valid_cells_{0}.pdf'.format(label))\n",
    "    (ggplot(df_ccs, aes('gene_aligned_target')) +\n",
    "        geom_bar(aes(fill='valid_cell'), position=pos) +\n",
    "        scale_fill_manual(COLOR_BLIND_PALETTE_GRAY[1 : ], name='valid cell') +\n",
    "        xlab(\"flu gene\") +\n",
    "        ylab(label + ' aligned CCSs') +\n",
    "        theme(axis_text_x=element_text(angle=90, hjust=0.5))\n",
    "        ).save(valid_cells_plot, width=3, height=2.25)\n",
    "    valid_cells_plots.append(valid_cells_plot)\n",
    "showPDF(valid_cells_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, a bit over half of the aligned CCSs correspond to valid cells, and there do not appear to be large differences among the flu genes.\n",
    "The fact that almost half aren't in valid cells isn't too surprising, as there are many empty GEMs that have some RNA but aren't called as cells.\n",
    "\n",
    "From here on out, we work just with the aligned CCSs in valid cells, so retain only those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccs = df_ccs.query('valid_cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-gene barcodes / UMI sampling\n",
    "We now want to examine how many times the typical cell barcode and UMI is observed, and also see if we expect to gain additional cell barcodes / UMIs if we sequence more.\n",
    "\n",
    "The UMIs are shorter than the cell barcodes, and in reality the cell barcodes can be thought of as an addition to the UMI since individual molecules must come from the same cell **and** have the same UMI.\n",
    "So we create a new variable called *UMI_long* that is the concatenation of the UMI and the cell barcode, and use this in place of just the UMI for identifying molecules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ccs['UMI_long'] = df_ccs.UMI + df_ccs.barcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for both these longer UMIs and the cell barcodes, we plot how many times each is observed and rarefaction plots of the saturation for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_obs = 4 # plot up to this many observations\n",
    "\n",
    "for prop, proplabel in [('barcode', 'cell barcode'), ('UMI_long', 'UMI')]:\n",
    "    \n",
    "    print(\"Number of times each {0} observed:\".format(proplabel))\n",
    "    df = (df_ccs\n",
    "         .groupby(['gene_aligned_target', prop], as_index=False)\n",
    "         .agg({'CCS':'count'})\n",
    "         .rename(columns={'CCS':'times_observed', prop:'number'})\n",
    "         .groupby(['gene_aligned_target', 'times_observed'], as_index=False)\n",
    "         .agg('count')\n",
    "         .assign(times_observed=lambda x:\n",
    "                 x.times_observed\n",
    "                 .clip(0, max_obs)\n",
    "                 .map(lambda n: str(n) if n < max_obs else '{0}+'.format(max_obs)))\n",
    "        )\n",
    "    nobservedplot = os.path.join(analysisdir, '{0}_nobserved.pdf'.format(proplabel))\n",
    "    (ggplot(df, aes('times_observed', 'number')) +\n",
    "        geom_bar(stat='identity') +\n",
    "        facet_wrap('gene_aligned_target', nrow=1) +\n",
    "        xlab('times {0} observed'.format(proplabel)) +\n",
    "        ylab('number of {0}s'.format(proplabel))\n",
    "        ).save(nobservedplot, width=13, height=3)\n",
    "    showPDF(nobservedplot)\n",
    "    \n",
    "    print(\"Rarefaction plot for {0}s:\".format(proplabel))\n",
    "    rarefyplot = os.path.join(analysisdir, '{0}_rarefaction.pdf'.format(proplabel))\n",
    "    dms_tools2.plot.plotRarefactionCurves(df_ccs, prop,\n",
    "            rarefyplot, facet_col='gene_aligned_target',\n",
    "            ylabel='number of {0}s'.format(proplabel), xlabel='number of CCSs',\n",
    "            nrow=2)\n",
    "    showPDF(rarefyplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots make clear that we are nowhere near saturation of the UMIs, very few are observed more than once and the rarefaction plots indicate no saturation.\n",
    "\n",
    "But for the cell barcodes, it appears that a majority of the barcodes that we observe are observed multiple times for all genes except the lowly expressed isoforms M2 and NS2.\n",
    "However, we are still not all that close to saturation of cell barcodes in the rarefaction plots--things are flattening off, but we could still clearly get more barcodes for all genes if we sequenced more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genes sequenced per cell\n",
    "We will now examine how completely the different genes are sequenced in each cell.\n",
    "\n",
    "Specifically, we want to determine how many genes are captured by cell, and which genes tend to be present or missing.\n",
    "Note that this analysis is limited to only cells in which at least one gene is captured.\n",
    "\n",
    "The M2 and NS2 isoforms are at very low abundance, and their sequences are actually included within the longer unspliced major M1 and NS2 isoforms.\n",
    "We therefore perform the analysis both on all isoforms and just the major isoforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze all flu genes, and just major isoforms\n",
    "all_isoforms = set(mapper.targetseqs.keys())\n",
    "major_isoforms = {sorted(isoforms)[0] for isoforms in mapper.target_isoforms.values()}\n",
    "print(\"Analyzing all {0} flu genes and just the {1} major isoforms ({2}).\"\n",
    "      .format(len(all_isoforms), len(major_isoforms), ', '.join(major_isoforms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for isoforms, isoform_desc in [\n",
    "        (all_isoforms, 'all'), (major_isoforms, 'major')]:\n",
    "\n",
    "    print(\"\\nAnalysis of {0} isoforms ({1} genes):\"\n",
    "          .format(isoform_desc, len(isoforms)))\n",
    "    \n",
    "    # calculate genes per cell\n",
    "    genes_per_cell = (\n",
    "        df_ccs\n",
    "        .query('gene_aligned_target in @isoforms')\n",
    "        .groupby(['barcode'])\n",
    "        .agg({'gene_aligned_target':lambda x: len(x.unique())})\n",
    "        .rename(columns={'gene_aligned_target':'number of flu genes'})\n",
    "        )\n",
    "    # calculate genes per cell conditioned on presence of each gene\n",
    "    genes_per_cell_by_gene = (\n",
    "        df_ccs\n",
    "        .query('gene_aligned_target in @isoforms')\n",
    "        .assign(has_gene=True,\n",
    "                gene_aligned_target=lambda x: \n",
    "                    x.gene_aligned_target.cat.remove_unused_categories())\n",
    "        [['barcode', 'gene_aligned_target', 'has_gene']]\n",
    "        .groupby(['barcode', 'gene_aligned_target'])\n",
    "        .agg('any').fillna(False)\n",
    "        .join(genes_per_cell)\n",
    "        .reset_index()\n",
    "        )\n",
    "\n",
    "    # plot distribution of genes per cell\n",
    "    plotwidth = 1 + 0.2 * len(isoforms)\n",
    "    genes_per_cell_plot = os.path.join(analysisdir,\n",
    "            '{0}_genes_per_cell.pdf'.format(isoform_desc))\n",
    "    (ggplot(genes_per_cell, aes('number of flu genes')) +\n",
    "        geom_histogram(binwidth=1) +\n",
    "        scale_x_continuous(breaks=range(1, len(isoforms) + 1)) +\n",
    "        ylab('number of cells')\n",
    "        ).save(genes_per_cell_plot, height=2.25, width=plotwidth)\n",
    "    showPDF(genes_per_cell_plot, 80 * plotwidth)\n",
    "    \n",
    "    # plot distribution of genes per cell faceted by gene presence\n",
    "    genes_per_cell_by_gene_plot = os.path.join(analysisdir,\n",
    "            '{0}_genes_per_cell_by_gene.pdf'.format(isoform_desc))\n",
    "    plotwidth=1 + len(isoforms)**2 * 0.1\n",
    "    (ggplot(genes_per_cell_by_gene,\n",
    "            aes('number of flu genes', fill='has_gene')) +\n",
    "        geom_histogram(binwidth=1) +\n",
    "        scale_x_continuous(breaks=range(1, len(isoforms) + 1)) +\n",
    "        ylab('number of cells') +\n",
    "        facet_wrap('~gene_aligned_target', nrow=2) +\n",
    "        scale_fill_manual(COLOR_BLIND_PALETTE_GRAY, name='has gene')\n",
    "        ).save(genes_per_cell_by_gene_plot, height=4.25, width=plotwidth)\n",
    "    showPDF(genes_per_cell_by_gene_plot, 80 * plotwidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call mutations\n",
    "We have already technically called mutations far above when we passed a `dms_tools2.minimap2.MutationCaller` to the `dms_tools2.pacbio.matchAndAlignSeqs` method used to create the data frame holding the results.\n",
    "We now want to examine these mutations and impose criteria (such as being observed in multiple sequences) to determine which ones are real.\n",
    "\n",
    "### Number of mutations per gene\n",
    "First, we simply calculate and plot the number of mutations called per aligned sequence for each gene and mutation type, also stratifying by the viral barcode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_muts = 3 # plot up to this many mutations\n",
    "\n",
    "nmuts_df = (\n",
    "    df_ccs\n",
    "    .assign(substitution=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.substitutions),\n",
    "            insertion=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.insertions),\n",
    "            deletion=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.deletions))\n",
    "    .melt(id_vars=['gene_aligned_target', 'viral_barcode'],\n",
    "          value_vars=['substitution', 'insertion', 'deletion'],\n",
    "          var_name='mutation_type', value_name='mutation_list')\n",
    "    # workaround melt / categorical bug: https://github.com/pandas-dev/pandas/issues/15853\n",
    "    .assign(gene_aligned_target=lambda x: pandas.Categorical(\n",
    "            x.gene_aligned_target, targetnames))\n",
    "    .assign(number=lambda x: x.mutation_list.map(len).clip(0, max_muts)\n",
    "            .map(lambda n: str(n) if n < max_muts else '{0}+'.format(max_muts)))\n",
    "    .assign(nseqs=1) # dummy variable for counting\n",
    "    .groupby(['gene_aligned_target', 'viral_barcode', 'mutation_type', 'number'])\n",
    "    .agg({'nseqs':'count'})\n",
    "    .assign(fraction=lambda x: # see https://stackoverflow.com/a/23377155\n",
    "                x.div(df_ccs.assign(nseqs=1)\n",
    "                              .groupby('gene_aligned_target')\n",
    "                              .agg({'nseqs':'count'}),\n",
    "                      'gene_aligned_target'))\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "nmuts_plot = os.path.join(analysisdir, 'nmuts_plot.pdf')\n",
    "(ggplot(nmuts_df, aes('number', 'fraction', fill='viral_barcode')) +\n",
    "    geom_bar(stat='identity', position=position_dodge()) +\n",
    "    facet_grid('mutation_type ~ gene_aligned_target') +\n",
    "    xlab('number of mutations') +\n",
    "    ylab('fraction of sequences') +\n",
    "    scale_fill_manual(COLOR_BLIND_PALETTE_GRAY[1 : ])\n",
    "    ).save(nmuts_plot, width=14, height=7)\n",
    "showPDF(nmuts_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that we almost always call at least one deletion for PB2, PB1, and PA.\n",
    "This is expected since these genes often have internal deletions. We also call a lot of deletions for HA, which is less expected. For the other genes, deletions are rarely called.\n",
    "\n",
    "We don't see many insertions (as perhaps expected).\n",
    "\n",
    "We see quite a few point substitutions, with the number probably about proportional to gene length (recalling that the polymerase genes are actually usually internally deleted in our data, and so not all that long). \n",
    "At our sequencing accuracy of 99.9% cutoff, we would expect about 1.5 point substitutions per gene for genes like HA, NP, and NA. \n",
    "In reality it is a bit higher, but of course some of this is probably due to their also being **real** point substitutions.\n",
    "In any case, the high substitution rate indicates that the sequences probably have an appreciable degree of errors from sequencing or PCR that we will need to correct somehow...\n",
    "\n",
    "The behavior of the two different viral barcodes generally looks comparable in terms of the distribution of mutations for all genes except the polymerase ones (where we already have observed that selective enrichment of certain deletions leads to some biases) and M2 / NS2 (where the counts are very low)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lengths of indels\n",
    "Now we look at the length distribution of the insertion and deletion mutations, again stratifying by gene and viral barcode.\n",
    "*A priori*, we might expect two kinds of mutations: very short indels (possibly due to sequencing errors), and longer internal deletions that are real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indel_len_df = (\n",
    "    df_ccs\n",
    "    .assign(insertion=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.insertions, returnval='length'),\n",
    "            deletion=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.deletions, returnval='length'))\n",
    "    .melt(id_vars=['gene_aligned_target', 'viral_barcode'],\n",
    "          value_vars=['insertion', 'deletion'],\n",
    "          var_name='mutation_type', value_name='mutation_length')\n",
    "    .groupby(['gene_aligned_target', 'viral_barcode', 'mutation_type'])\n",
    "    .mutation_length\n",
    "    .sum()\n",
    "    # column of lists to long form: https://stackoverflow.com/a/27266225\n",
    "    .apply(pandas.Series)\n",
    "    .stack()\n",
    "    .rename('length')\n",
    "    .reset_index()\n",
    "    # workaround melt / categorical bug: https://github.com/pandas-dev/pandas/issues/15853\n",
    "    .assign(gene_aligned_target=lambda x: pandas.Categorical(\n",
    "            x.gene_aligned_target, targetnames))\n",
    "    ) \n",
    "    \n",
    "indel_len_plot = os.path.join(analysisdir, 'indel_len_plot.pdf')\n",
    "(ggplot(indel_len_df, aes('length', fill='viral_barcode')) +\n",
    "    geom_histogram(aes(y='..density..')) +\n",
    "    facet_grid('mutation_type ~ gene_aligned_target') +\n",
    "    ylab('relative fraction') +\n",
    "    scale_y_continuous(breaks=None) +\n",
    "    scale_x_log10(labels=lambda x: x.astype('int') \n",
    "                  if all(x.astype('int') == x) else x) +\n",
    "    scale_fill_manual(COLOR_BLIND_PALETTE_GRAY[1 : ])\n",
    "    ).save(indel_len_plot, width=14, height=4)\n",
    "showPDF(indel_len_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots are consistent with virtually all of the insertions being very short, plausibly due to sequencing errors.\n",
    "For most genes, most the deletions are also very short and plausibly due to sequencing errors.\n",
    "However, for some genes (especially the polymerase genes but also to some extent HA and a few others), many of the deletions are very long and unlikely to be sequencing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of mutations\n",
    "Below we compute the distributions of accuracies for mutations from the Q-values, and then plot the error rate (1 minus the accuracy) for these mutations.\n",
    "We also do this for **all** sites in the genes.\n",
    "\n",
    "First, plot the accuracy of all sites in the aligned genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error_rate = 1e-4 # plot error rates down to this low\n",
    "\n",
    "# data frame with accuracies of all sites\n",
    "all_acc_df = (\n",
    "    pandas.DataFrame({\n",
    "        'accuracy':dms_tools2.pacbio.qvalsToAccuracy(df_ccs\n",
    "                    .gene_qvals.apply(pandas.Series).stack().values,\n",
    "                    no_avg=True)})\n",
    "    .assign(error_rate=lambda x: 1 - x.accuracy.clip(upper=1 - min_error_rate))\n",
    "    )\n",
    "\n",
    "# cumulative fraction plot\n",
    "all_acc_plot = os.path.join(analysisdir, 'all_acc_plot.pdf')\n",
    "(ggplot(all_acc_df, aes('error_rate')) +\n",
    "    stat_ecdf() +\n",
    "    ylab('cumulative fraction') +\n",
    "    scale_x_log10() +\n",
    "    scale_y_continuous(limits=(0.5, 1)) \n",
    "    ).save(all_acc_plot, width=3, height=2)\n",
    "showPDF(all_acc_plot, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the above plot, the vast majority of sites have accuracies > 99.99%.\n",
    "\n",
    "Now we make the same plot for just the accuracy of the mutated sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_acc_df = (\n",
    "    df_ccs\n",
    "    .assign(insertion=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.insertions, returnval='accuracy'),\n",
    "            deletion=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.deletions, returnval='accuracy'),\n",
    "            substitution=lambda x: x.gene_aligned_mutations.apply(\n",
    "                    dms_tools2.minimap2.Mutations.substitutions, returnval='accuracy'))\n",
    "    .melt(id_vars=['gene_aligned_target', 'viral_barcode'],\n",
    "          value_vars=['insertion', 'deletion', 'substitution'],\n",
    "          var_name='mutation_type', value_name='accuracy')\n",
    "    .groupby(['gene_aligned_target', 'viral_barcode', 'mutation_type'])\n",
    "    .accuracy\n",
    "    .sum()\n",
    "    # column of lists to long form: https://stackoverflow.com/a/27266225\n",
    "    .apply(pandas.Series)\n",
    "    .stack()\n",
    "    .rename('accuracy')\n",
    "    .reset_index()\n",
    "    # workaround melt / categorical bug: https://github.com/pandas-dev/pandas/issues/15853\n",
    "    .assign(gene_aligned_target=lambda x: pandas.Categorical(\n",
    "            x.gene_aligned_target, targetnames))\n",
    "    .assign(error_rate=lambda x: 1 - x.accuracy.clip(upper=1 - min_error_rate))\n",
    "    )\n",
    "\n",
    "mut_acc_plot = os.path.join(analysisdir, 'mut_acc_plot.pdf')\n",
    "(ggplot(mut_acc_df, aes('error_rate', color='viral_barcode')) +\n",
    "    stat_ecdf() +\n",
    "    facet_grid('mutation_type ~ gene_aligned_target') +\n",
    "    ylab('cumulative fraction') +\n",
    "    scale_x_log10() +\n",
    "    scale_y_continuous(limits=(0.5, 1)) +\n",
    "    scale_color_manual(COLOR_BLIND_PALETTE_GRAY[1 : ])\n",
    "    ).save(mut_acc_plot, width=14, height=4)\n",
    "showPDF(mut_acc_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, for many types of mutations the accuracies of the mutations are clearly lower.\n",
    "This is the case for the insertions, the deletions in most genes other than the polymerase genes (which probably have long real deletions), and to a lesser degree for the substitution mutations.\n",
    "\n",
    "This provides evidence that at least a reasonable fraction of sites that we call as having mutations really are lower accuracy mis-calls, and also suggests that taking the accuracies (Q-values) into account may be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze flu sequences at cell level\n",
    "Now we want to analyze the results at the level of cells.\n",
    "In particular, we want to try to build up accurate calls of the full sequences of the flu genes in individual infected cells.\n",
    "Because it appears that individual CCSs may not be sufficiently accurate to call these, we in particular look for cells where we have multiple CCSs to take the consensus of these for the cell.\n",
    "\n",
    "Of course, this approach of building consensus of CCSs from the same cell depends on the assumption that the cell was only infected by a single virion (only sometimes true based on the analyses with `Monocle`...) and that _de novo_ mutations did not arise rapidly in the first few rounds of genome replication after infection (probably usually true given what is known about the virus's mutation rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate data at the cell level\n",
    "First, we aggregate the information for each cell barcode, flu gene, and viral barcode into a new data frame called *df_cells*.\n",
    "We aggregate by cell barcode and flu gene because we would like to build the consensus for each flu gene for each cell, and we aggregate by viral barcode because if genes come from different viral barcodes then we know that the cell must have been infected by multiple virions, one of each viral barcode (note that there could also be some cells infected by multiple virions of the same barcode that we won't catch).\n",
    "\n",
    "For each cell barcode, flu gene, and viral barcode we calculate the number of valid aligned sequences and a list of the mutations called in each of these CCSs.\n",
    "We also calculate the number of valid aligned sequences that are also **full length**, using the criterion for full length sequences defined earlier in this notebook (this is important since for some genes such as the polymerase ones, our sequencing may be highly biased against full-length sequences).\n",
    "\n",
    "Also, because we know that we have very low levels of the minor isoforms M2 and NS2, and because sequences of the major isoforms M1 and NS1 contain the full sequences of M2 and NS2 as well, we also make a column called *major_isoform* which is true only if a flu gene is a major isoform.\n",
    "We will then perform many of our operations only on these major isoforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cells = (\n",
    "    df_ccs\n",
    "    .groupby(['barcode', 'gene_aligned_target', 'viral_barcode'])\n",
    "    .apply(lambda x: pandas.Series({ # following https://stackoverflow.com/a/47103408\n",
    "        'n_sequences':x.gene.count(),\n",
    "        'n_sequences_full_length':x.full_length.sum(),\n",
    "        'mutation_list':list(x.gene_aligned_mutations)\n",
    "        }))\n",
    "    .query('n_sequences > 0')\n",
    "    .reset_index()\n",
    "    .assign(major_isoform=lambda x: x.gene_aligned_target.isin(major_isoforms))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genes sequenced per cell\n",
    "Now for each cell and viral barcode, we tally how many genes are observed at least *N* times for several values of the threshold *N*.\n",
    "We do this counting **only** for the major isoforms, so the most genes that can be observed are eight.\n",
    "The reason that we tally the number of genes observed for several thresholds is to figure out how many cells we'll retain if we impose various different criterion for how many sequences we take the consensus of to call mutations.\n",
    "\n",
    "We do this both for all sequences and for full-length sequences only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tally how many genes observed >= this many times for each cell\n",
    "n_obs = [1, 2, 3]\n",
    "n_obs_labels = ['at least {0} sequence{1}'.format(\n",
    "        n, 's' if n > 1 else '') for n in n_obs]\n",
    "n_obs_cols = {\n",
    "    'all_lengths':['n_genes_ge_{0}'.format(n) for n in n_obs],\n",
    "    'full_length':['n_genes_ge_{0}_full_length'.format(n) for n in n_obs]\n",
    "    }\n",
    "\n",
    "for nseq_col, cols in [\n",
    "        ('n_sequences', n_obs_cols['all_lengths']),\n",
    "        ('n_sequences_full_length', n_obs_cols['full_length'])]:\n",
    "    for nobs, col in zip(n_obs, cols):\n",
    "        df_cells[col] = (\n",
    "            df_cells\n",
    "            .assign(count_gene=lambda x: # major isoform observed enough? \n",
    "                    x.major_isoform & (x[nseq_col] >= nobs))\n",
    "            .groupby(['barcode', 'viral_barcode'])\n",
    "            .count_gene\n",
    "            .transform('sum')\n",
    "            .astype('int')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the number of cells with a given number of genes sequenced for several thresholds for how many sequences we require per gene.\n",
    "We make these plots both for any sequence, and requiring full-length sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with number of gene and full-length genes per cell\n",
    "gene_counts_df = (\n",
    "    df_cells\n",
    "    .melt(id_vars=['barcode', 'viral_barcode'],\n",
    "          value_vars=n_obs_cols['all_lengths'] + n_obs_cols['full_length'],\n",
    "          var_name='minimum_observations',\n",
    "          value_name='number of flu genes')\n",
    "    .assign(full_length_only=lambda x: numpy.where(\n",
    "          x.minimum_observations.isin(n_obs_cols['full_length']),\n",
    "          'full length only', 'all lengths'))\n",
    "    .assign(minimum_observations=lambda x: x.minimum_observations\n",
    "          .replace(dict(zip(n_obs_cols['all_lengths'], n_obs_labels)))\n",
    "          .replace(dict(zip(n_obs_cols['full_length'], n_obs_labels))))\n",
    "    )\n",
    "\n",
    "gene_counts_plot = os.path.join(analysisdir, 'gene_counts.pdf')\n",
    "(ggplot(gene_counts_df, aes('number of flu genes', fill='viral_barcode')) +\n",
    "    geom_bar(position=position_dodge()) +\n",
    "    facet_grid('full_length_only ~ minimum_observations') +\n",
    "    scale_x_continuous(limits=(0.5, len(major_isoforms) + 0.5),\n",
    "        breaks=list(range(1, len(major_isoforms) + 1))) +\n",
    "    ylab(\"number of cells\") +\n",
    "    scale_fill_manual(COLOR_BLIND_PALETTE_GRAY[1 : ])\n",
    "    ).save(gene_counts_plot, height=4.25, width=2 * (1 + len(n_obs)))\n",
    "showPDF(gene_counts_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for a reasonable number of cells, we have all 8 genes sequenced multiple times.\n",
    "This might be even better than it initially seems, if we recall (as detailed more in the `Monocle` analysis) that some cells simply fail to express all viral genes.\n",
    "This bodes well for calling viral genome sequences from these cells using the consensus of multiple CCSs.\n",
    "\n",
    "Unfortunately, we see that things are much worse when we limit ourselves to full-length sequences only.\n",
    "Part of the reason may be that some cells are simply infected by viruses with internal deletions.\n",
    "But based on the data above showing the polymerase gene sequences are very highly biased towards internal deletions, probably the larger factor is that the sequencing is doing a very poor job of capturing full-length polymerase sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_cells.query('n_sequences > 2').reset_index(drop=True).mutation_list\n",
    "for i in range(0):\n",
    "    mutlist = list(map(dms_tools2.minimap2.Mutations.substitutions, x.ix[i]))\n",
    "    muts = collections.Counter([m for ml in mutlist for m in ml])\n",
    "    if max(muts.values()) > 1:\n",
    "        print(len(mutlist), '\\n', muts, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1004px",
    "left": "0px",
    "right": "1214px",
    "top": "110px",
    "width": "271px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
